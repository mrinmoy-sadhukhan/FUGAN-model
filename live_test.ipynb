{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "#from imutils import face_utils \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "#from keras.optimizers import adam\n",
    "from keras.layers import Input, Conv2D, UpSampling2D, Dropout, LeakyReLU, BatchNormalization, Activation, Lambda, Conv2DTranspose\n",
    "from keras.layers import Concatenate\n",
    "from keras import backend as K\n",
    "#from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import PIL\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras_preprocessing.image import array_to_img\n",
    "#from tensorflow.python.client import device_lib\n",
    "\n",
    "#print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_load(image_file):\n",
    "    \"\"\"\n",
    "    image load, 하나의 이미지로 된 real_image, mask_image 분할\n",
    "    \"\"\"\n",
    "    # Read and decode an image file to a uint8 tensor\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations = False)\n",
    "\n",
    "    #w = tf.shape(image)[1]\n",
    "    #w = w // 2\n",
    "\n",
    "    #real_image = image[:, w:, :]\n",
    "    #mask_image = image[:, :w, :]\n",
    "\n",
    "    # Convert both images to float32 tensors\n",
    "    mask_image = tf.cast(image, tf.float32)\n",
    "    #real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_load(image_file):\n",
    "    \"\"\"\n",
    "    Binary image load\n",
    "    \"\"\"\n",
    "    # Read and decode an image file to a uint8 tensor\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_image(image, channels=3, expand_animations = False)\n",
    "\n",
    "    input_image = image[:, :, :]\n",
    "\n",
    "    # Convert both images to float32 tensors\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_normalize(input_image, real_image, height, width):\n",
    "  \"\"\"\n",
    "  image resize and [-1 ~ 1] normalize\n",
    "  \"\"\"\n",
    "  if real_image is not None:\n",
    "    input_image = tf.image.resize(input_image, [height, width],preserve_aspect_ratio=False,\n",
    "                                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],preserve_aspect_ratio=False,\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "    return input_image, real_image\n",
    "\n",
    "  else:\n",
    "    input_image = tf.image.resize(input_image, [height, width],preserve_aspect_ratio=False,\n",
    "                              method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # TF 2.0\n",
    "\n",
    "\n",
    "class SpectralNormalization(tf.keras.layers.Wrapper):\n",
    "    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n",
    "        self.iteration = iteration\n",
    "        self.eps = eps\n",
    "        self.do_power_iteration = training\n",
    "        if not isinstance(layer, tf.keras.layers.Layer):\n",
    "            raise ValueError(\n",
    "                'Please initialize `TimeDistributed` layer with a '\n",
    "                '`Layer` instance. You passed: {input}'.format(input=layer))\n",
    "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer.build(input_shape)\n",
    "\n",
    "        self.w = self.layer.kernel\n",
    "        self.w_shape = self.w.shape.as_list()\n",
    "\n",
    "        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_v',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_u',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        super(SpectralNormalization, self).build()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.update_weights()\n",
    "        output = self.layer(inputs)\n",
    "        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n",
    "        return output\n",
    "    \n",
    "    def update_weights(self):\n",
    "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
    "        \n",
    "        u_hat = self.u\n",
    "        v_hat = self.v  # init v vector\n",
    "\n",
    "        if self.do_power_iteration:\n",
    "            for _ in range(self.iteration):\n",
    "                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n",
    "                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n",
    "\n",
    "                u_ = tf.matmul(v_hat, w_reshaped)\n",
    "                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n",
    "\n",
    "        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n",
    "        self.u.assign(u_hat)\n",
    "        self.v.assign(v_hat)\n",
    "\n",
    "        self.layer.kernel.assign(self.w / sigma)\n",
    "\n",
    "    def restore_weights(self):\n",
    "        self.layer.kernel.assign(self.w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.v1.contrib as tf_contrib\n",
    "\n",
    "\n",
    "# Xavier : tf_contrib.layers.xavier_initializer()\n",
    "# He : tf_contrib.layers.variance_scaling_initializer()\n",
    "# Normal : tf.random_normal_initializer(mean=0.0, stddev=0.02)\n",
    "# l2_decay : tf_contrib.layers.l2_regularizer(0.0001)\n",
    "\n",
    "weight_init = tf.compat.v1.keras.initializers.glorot_normal\n",
    "weight_regularizer = None\n",
    "weight_regularizer_fully = None\n",
    "\n",
    "##################################################################################\n",
    "# Layer\n",
    "##################################################################################\n",
    "\n",
    "def conv(x, channels, kernel=4, stride=2, pad=0, pad_type='zero', use_bias=True, sn=False, scope='conv_0'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        if pad > 0:\n",
    "            h = x.get_shape().as_list()[1]\n",
    "            if h % stride == 0:\n",
    "                pad = pad * 2\n",
    "            else:\n",
    "                pad = max(kernel - (h % stride), 0)\n",
    "\n",
    "            pad_top = pad // 2\n",
    "            pad_bottom = pad - pad_top\n",
    "            pad_left = pad // 2\n",
    "            pad_right = pad - pad_left\n",
    "\n",
    "            if pad_type == 'zero':\n",
    "                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]])\n",
    "            if pad_type == 'reflect':\n",
    "                x = tf.pad(x, [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], mode='REFLECT')\n",
    "\n",
    "        if sn:\n",
    "            w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel, kernel, x.get_shape()[-1], channels], initializer=weight_init,\n",
    "                                regularizer=weight_regularizer)\n",
    "            x = tf.nn.conv2d(input=x, filters=spectral_norm(w),\n",
    "                             strides=[1, stride, stride, 1], padding='VALID')\n",
    "            if use_bias:\n",
    "                bias = tf.compat.v1.get_variable(\"bias\", [channels], initializer=tf.constant_initializer(0.0))\n",
    "                x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "        else:\n",
    "            x = tf.layers.conv2d(inputs=x, filters=channels,\n",
    "                                 kernel_size=kernel, kernel_initializer=weight_init,\n",
    "                                 kernel_regularizer=weight_regularizer,\n",
    "                                 strides=stride, use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def deconv(x, channels, kernel=4, stride=2, padding='SAME', use_bias=True, sn=False, scope='deconv_0'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        x_shape = x.get_shape().as_list()\n",
    "\n",
    "        if padding == 'SAME':\n",
    "            output_shape = [x_shape[0], x_shape[1] * stride, x_shape[2] * stride, channels]\n",
    "\n",
    "        else:\n",
    "            output_shape = [x_shape[0], x_shape[1] * stride + max(kernel - stride, 0),\n",
    "                            x_shape[2] * stride + max(kernel - stride, 0), channels]\n",
    "\n",
    "        if sn:\n",
    "            w = tf.compat.v1.get_variable(\"kernel\", shape=[kernel, kernel, channels, x.get_shape()[-1]], initializer=weight_init,\n",
    "                                regularizer=weight_regularizer)\n",
    "            x = tf.nn.conv2d_transpose(x, filters=spectral_norm(w), output_shape=output_shape,\n",
    "                                       strides=[1, stride, stride, 1], padding=padding)\n",
    "\n",
    "            if use_bias:\n",
    "                bias = tf.compat.v1.get_variable(\"bias\", [channels], initializer=tf.constant_initializer(0.0))\n",
    "                x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "        else:\n",
    "            x = tf.layers.conv2d_transpose(inputs=x, filters=channels,\n",
    "                                           kernel_size=kernel, kernel_initializer=weight_init,\n",
    "                                           kernel_regularizer=weight_regularizer,\n",
    "                                           strides=stride, padding=padding, use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def fully_connected(x, units, use_bias=True, sn=False, scope='linear'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        x = flatten(x)\n",
    "        shape = x.get_shape().as_list()\n",
    "        channels = shape[-1]\n",
    "\n",
    "        if sn:\n",
    "            w = tf.compat.v1.get_variable(\"kernel\", [channels, units], tf.float32,\n",
    "                                initializer=weight_init, regularizer=weight_regularizer_fully)\n",
    "            if use_bias:\n",
    "                bias = tf.compat.v1.get_variable(\"bias\", [units],\n",
    "                                       initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                x = tf.matmul(x, spectral_norm(w)) + bias\n",
    "            else:\n",
    "                x = tf.matmul(x, spectral_norm(w))\n",
    "\n",
    "        else:\n",
    "            x = tf.layers.dense(x, units=units, kernel_initializer=weight_init,\n",
    "                                kernel_regularizer=weight_regularizer_fully,\n",
    "                                use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def flatten(x) :\n",
    "    return tf.layers.flatten(x)\n",
    "\n",
    "def hw_flatten(x) :\n",
    "    x_shape=tf.shape(x)\n",
    "    return tf.reshape(x, [x_shape[0], -1, x_shape[-1]])\n",
    "\n",
    "##################################################################################\n",
    "# Residual-block\n",
    "##################################################################################\n",
    "\n",
    "def up_resblock(x_init, channels, use_bias=True, is_training=True, sn=False, scope='resblock'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        with tf.compat.v1.variable_scope('res1'):\n",
    "            x = batch_norm(x_init, is_training)\n",
    "            x = relu(x)\n",
    "            x = up_sample(x, scale_factor=2)\n",
    "            x = conv(x, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=False, sn=sn)\n",
    "\n",
    "        with tf.compat.v1.variable_scope('res2'):\n",
    "            x = batch_norm(x, is_training)\n",
    "            x = relu(x)\n",
    "            x = conv(x, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=use_bias, sn=sn)\n",
    "\n",
    "        with tf.compat.v1.variable_scope('shortcut'):\n",
    "            x_init = up_sample(x_init, scale_factor=2)\n",
    "            x_init = conv(x_init, channels, kernel=1, stride=1, use_bias=False, sn=sn)\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "def down_resblock(x_init, channels, to_down=True, use_bias=True, sn=False, scope='resblock'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        init_channel = x_init.shape.as_list()[-1]\n",
    "        with tf.compat.v1.variable_scope('res1'):\n",
    "            x = lrelu(x_init, 0.2)\n",
    "            x = conv(x, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=use_bias, sn=sn)\n",
    "\n",
    "        with tf.compat.v1.variable_scope('res2'):\n",
    "            x = lrelu(x, 0.2)\n",
    "            x = conv(x, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=use_bias, sn=sn)\n",
    "\n",
    "            if to_down :\n",
    "                x = down_sample(x)\n",
    "\n",
    "        if to_down or init_channel != channels :\n",
    "            with tf.compat.v1.variable_scope('shortcut'):\n",
    "                x_init = conv(x_init, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn)\n",
    "                if to_down :\n",
    "                    x_init = down_sample(x_init)\n",
    "\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "def init_down_resblock(x_init, channels, use_bias=True, sn=False, scope='resblock'):\n",
    "    with tf.compat.v1.variable_scope(scope):\n",
    "        with tf.compat.v1.variable_scope('res1'):\n",
    "            x = conv(x_init, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=use_bias, sn=sn)\n",
    "            x = lrelu(x, 0.2)\n",
    "\n",
    "        with tf.compat.v1.variable_scope('res2'):\n",
    "            x = conv(x, channels, kernel=3, stride=1, pad=1, pad_type='reflect', use_bias=use_bias, sn=sn)\n",
    "            x = down_sample(x)\n",
    "\n",
    "        with tf.compat.v1.variable_scope('shortcut'):\n",
    "            x_init = down_sample(x_init)\n",
    "            x_init = conv(x_init, channels, kernel=1, stride=1, use_bias=use_bias, sn=sn)\n",
    "\n",
    "        return x + x_init\n",
    "\n",
    "##################################################################################\n",
    "# Sampling\n",
    "##################################################################################\n",
    "\n",
    "def global_avg_pooling(x):\n",
    "    gap = tf.reduce_mean(x, axis=[1, 2])\n",
    "\n",
    "    return gap\n",
    "\n",
    "def global_sum_pooling(x) :\n",
    "    gsp = tf.reduce_sum(x, axis=[1, 2])\n",
    "\n",
    "    return gsp\n",
    "\n",
    "def up_sample(x, scale_factor=2):\n",
    "    _, h, w, _ = x.get_shape().as_list()\n",
    "    new_size = [h * scale_factor, w * scale_factor]\n",
    "    return tf.image.resize_nearest_neighbor(x, size=new_size)\n",
    "\n",
    "def down_sample(x):\n",
    "    return tf.compat.v1.layers.average_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "def max_pooling(x) :\n",
    "    return tf.compat.v1.layers.max_pooling2d(x, pool_size=2, strides=2, padding='SAME')\n",
    "\n",
    "##################################################################################\n",
    "# Activation function\n",
    "##################################################################################\n",
    "\n",
    "def lrelu(x, alpha=0.2):\n",
    "    return tf.nn.leaky_relu(x, alpha)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return tf.tanh(x)\n",
    "\n",
    "##################################################################################\n",
    "# Normalization function\n",
    "##################################################################################\n",
    "\n",
    "def batch_norm(x, is_training=True, scope='batch_norm'):\n",
    "    return tf.compat.v1.layers.batch_norm(x,\n",
    "                                        decay=0.9, epsilon=1e-05,\n",
    "                                        center=True, scale=True, updates_collections=None,\n",
    "                                        is_training=is_training, scope=scope)\n",
    "\n",
    "def spectral_norm(w, iteration=1):\n",
    "    w_shape = w.shape.as_list()\n",
    "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
    "\n",
    "    u = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.random_normal_initializer(), trainable=False)\n",
    "\n",
    "    u_hat = u\n",
    "    v_hat = None\n",
    "    for i in range(iteration):\n",
    "        \"\"\"\n",
    "        power iteration\n",
    "        Usually iteration = 1 will be enough\n",
    "        \"\"\"\n",
    "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
    "        v_hat = tf.nn.l2_normalize(v_)\n",
    "\n",
    "        u_ = tf.matmul(v_hat, w)\n",
    "        u_hat = tf.nn.l2_normalize(u_)\n",
    "\n",
    "    u_hat = tf.stop_gradient(u_hat)\n",
    "    v_hat = tf.stop_gradient(v_hat)\n",
    "\n",
    "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
    "\n",
    "    with tf.control_dependencies([u.assign(u_hat)]):\n",
    "        w_norm = w / sigma\n",
    "        w_norm = tf.reshape(w_norm, w_shape)\n",
    "\n",
    "    return w_norm\n",
    "\n",
    "##################################################################################\n",
    "# Loss function\n",
    "##################################################################################\n",
    "\n",
    "def discriminator_loss(loss_func, real, fake):\n",
    "    real_loss = 0\n",
    "    fake_loss = 0\n",
    "\n",
    "    if loss_func.__contains__('wgan') :\n",
    "        real_loss = -tf.reduce_mean(real)\n",
    "        fake_loss = tf.reduce_mean(fake)\n",
    "\n",
    "    if loss_func == 'lsgan' :\n",
    "        real_loss = tf.reduce_mean(tf.squared_difference(real, 1.0))\n",
    "        fake_loss = tf.reduce_mean(tf.square(fake))\n",
    "\n",
    "    if loss_func == 'gan' or loss_func == 'dragan' :\n",
    "        real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(real), logits=real))\n",
    "        fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(fake), logits=fake))\n",
    "\n",
    "    if loss_func == 'hinge' :\n",
    "        real_loss = tf.reduce_mean(relu(1.0 - real))\n",
    "        fake_loss = tf.reduce_mean(relu(1.0 + fake))\n",
    "\n",
    "    loss = real_loss + fake_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "def generator_loss(loss_func, fake):\n",
    "    fake_loss = 0\n",
    "\n",
    "    if loss_func.__contains__('wgan') :\n",
    "        fake_loss = -tf.reduce_mean(fake)\n",
    "\n",
    "    if loss_func == 'lsgan' :\n",
    "        fake_loss = tf.reduce_mean(tf.squared_difference(fake, 1.0))\n",
    "\n",
    "    if loss_func == 'gan' or loss_func == 'dragan' :\n",
    "        fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(fake), logits=fake))\n",
    "\n",
    "    if loss_func == 'hinge' :\n",
    "        fake_loss = -tf.reduce_mean(fake)\n",
    "\n",
    "    loss = fake_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_instance_norm(x, scope='batch_instance_norm'):\n",
    "    \n",
    "    with tf.compat.v1.variable_scope(scope,reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        ch = x.shape[-1]\n",
    "        eps = 1e-5\n",
    "\n",
    "        batch_mean, batch_sigma = tf.nn.moments(x, axes=[0, 1, 2], keepdims=True)\n",
    "        x_batch = (x - batch_mean) / (tf.sqrt(batch_sigma + eps))\n",
    "\n",
    "        ins_mean, ins_sigma = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_ins = (x - ins_mean) / (tf.sqrt(ins_sigma + eps))\n",
    "\n",
    "        rho = tf.compat.v1.get_variable(\"rho\", [ch], initializer=tf.constant_initializer(1.0), constraint=lambda x: tf.clip_by_value(x, clip_value_min=0.0, clip_value_max=1.0))\n",
    "        gamma = tf.compat.v1.get_variable(\"gamma\", [ch], initializer=tf.constant_initializer(1.0))\n",
    "        beta = tf.compat.v1.get_variable(\"beta\", [ch], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        x_hat = rho * x_batch + (1 - rho) * x_ins\n",
    "        x_hat = x_hat * gamma + beta\n",
    "\n",
    "        return x_hat\n",
    "\n",
    "def attention1(x,channels,scope='attention'):\n",
    "    \n",
    "    ##more like google attention it is hybrid version\n",
    "    with tf.compat.v1.variable_scope(scope,reuse=tf.compat.v1.AUTO_REUSE):\n",
    "\n",
    "        f = conv(x, channels // 8, kernel=1, stride=1, sn=True, scope=scope+'f_conv') # [bs, h, w, c']\n",
    "        g = conv(x, channels // 8, kernel=1, stride=1, sn=True, scope=scope+'g_conv') # [bs, h, w, c']\n",
    "        h = conv(x, channels // 2, kernel=1, stride=1, sn=True, scope=scope+'h_conv') # [bs, h, w, c\n",
    "        gamma=tf.compat.v1.get_variable(\"gamma\", [1], initializer=tf.constant_initializer(0.0))\n",
    "        f_flatten = hw_flatten(f)\n",
    "        g_flatten = hw_flatten(g)\n",
    "        h_flatten = hw_flatten(h)\n",
    "        \n",
    "        s = tf.matmul(g_flatten, f_flatten, transpose_b=True) # [B,N,C] * [B, N, C] = [B, N, N]\n",
    "        b = tf.nn.softmax(s, axis=-1)\n",
    "        o = tf.matmul(b, h_flatten)\n",
    "        batch_size, height, width, num_channels = x.get_shape().as_list()\n",
    "        o = tf.reshape(o, tf.shape(x))\n",
    "        o = conv(o,channels // 2,kernel=1,stride=1,sn=True,scope=scope+\"attn_conv\")\n",
    "        y = gamma * o + x\n",
    "\n",
    "\n",
    "            \n",
    "        return y\n",
    "\n",
    "class maskgeneration:\n",
    "    def prepare_model(self, input_size=(128,128,3),start_channel=32):\n",
    "        inputs = tf.keras.layers.Input(input_size)\n",
    "        s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "        c0 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(s) ##input channel 3 output 16\n",
    "        c0 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c0) ##input channel 3 output 16 \n",
    "        c0 = batch_instance_norm(c0)\n",
    "        c0 = tf.nn.leaky_relu(c0)\n",
    "        p0 = tf.keras.layers.MaxPooling2D((2,2))(c0)\n",
    "        #Contraction path\n",
    "        c1 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p0) ##input channel 3 output 16\n",
    "        c1 = batch_instance_norm(c1)\n",
    "        c1 = tf.nn.leaky_relu(c1)\n",
    "        c1 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c1) ##------>\n",
    "        c1 = batch_instance_norm(c1)\n",
    "        c1 = tf.nn.leaky_relu(c1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1) ##\n",
    "\n",
    "        c2 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p1)\n",
    "        c2 = batch_instance_norm(c2)\n",
    "        c2 = tf.nn.leaky_relu(c2)\n",
    "        c2 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c2) ##------>\n",
    "        c2 = batch_instance_norm(c2)\n",
    "        c2 = tf.nn.leaky_relu(c2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2) ##\n",
    "        \n",
    "        #c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "        c3 = attention1(x=p2,channels=start_channel*8,scope='self_attention')\n",
    "        c3 = batch_instance_norm(c3)\n",
    "        c3 = tf.nn.leaky_relu(c3)\n",
    "        c3 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c3) ##----->\n",
    "        c3 = batch_instance_norm(c3)\n",
    "        c3 = tf.nn.leaky_relu(c3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3) ##\n",
    "        \n",
    "        #c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "        c4 = attention1(x=p3,channels=start_channel*16,scope='self_attention')\n",
    "        c4 = batch_instance_norm(c4)\n",
    "        c4 = tf.nn.leaky_relu(c4)\n",
    "        c4 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c4) ##----->\n",
    "        c4 = batch_instance_norm(c4)\n",
    "        c4 = tf.nn.leaky_relu(c4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4) ##\n",
    "\n",
    "        ##Bottelneck \n",
    "        c5 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p4)\n",
    "        c5 = batch_instance_norm(c5)\n",
    "        c5 = tf.nn.leaky_relu(c5)\n",
    "        c5 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c5) ##----->\n",
    "        c5 = batch_instance_norm(c5)\n",
    "        c5 = tf.nn.leaky_relu(c5)\n",
    "\n",
    "        #Expansive path \n",
    "        u6 = tf.keras.layers.Conv2DTranspose(start_channel*16, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "        c6 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u6)\n",
    "        c6 = batch_instance_norm(c6)\n",
    "        c6 = tf.nn.leaky_relu(c6)\n",
    "        c6 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c6) ##------>\n",
    "        c6 = batch_instance_norm(c6)\n",
    "        c6 = tf.nn.leaky_relu(c6)\n",
    "        \n",
    "        u7 = tf.keras.layers.Conv2DTranspose(start_channel*8, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "        c7 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u7)\n",
    "        c7 = batch_instance_norm(c7)\n",
    "        c7 = tf.nn.leaky_relu(c7)\n",
    "        c7 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c7)\n",
    "        c7 = batch_instance_norm(c7)\n",
    "        c7 = tf.nn.leaky_relu(c7)\n",
    "        \n",
    "        u8 = tf.keras.layers.Conv2DTranspose(start_channel*4, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "        c8 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u8)\n",
    "        c8 = batch_instance_norm(c8)\n",
    "        c8 = tf.nn.leaky_relu(c8)\n",
    "        c8 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c8)\n",
    "        c8 = batch_instance_norm(c8)\n",
    "        c8 = tf.nn.leaky_relu(c8)\n",
    "        \n",
    "        u9 = tf.keras.layers.Conv2DTranspose(start_channel*2, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "        c9 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u9)\n",
    "        c9 = batch_instance_norm(c9)\n",
    "        c9 = tf.nn.leaky_relu(c9)\n",
    "        c9 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c9)\n",
    "        c9 = batch_instance_norm(c9)\n",
    "        c9 = tf.nn.leaky_relu(c9)\n",
    "\n",
    "        u10 = tf.keras.layers.Conv2DTranspose(start_channel, (2, 2), strides=(2, 2), padding='same')(c9)\n",
    "        u10 = tf.keras.layers.concatenate([u10, c0], axis=3)\n",
    "        c10 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u10)\n",
    "        c10 = batch_instance_norm(c10)\n",
    "        c10 = tf.nn.leaky_relu(c10)\n",
    "        c10 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c10)\n",
    "        c10 = batch_instance_norm(c10)\n",
    "        c10 = tf.nn.leaky_relu(c10)\n",
    "        #initializer = tf.random_normal_initializer(0., 0.02)\n",
    "        #outputs= tf.keras.layers.Conv2DTranspose(3, 3,strides=2,padding='same',kernel_initializer=initializer,activation='tanh')(c10)\n",
    "        outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "        \n",
    "        return tf.keras.models.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_2), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_3), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_5), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_7), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_8), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_11), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_11), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_15), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_14), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_19), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionf_conv/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_1), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentiong_conv/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_2), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionh_conv/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_3), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionattn_conv/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_18), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_24), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_21), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_28), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_4), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionf_conv/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_5), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentiong_conv/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_6), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionh_conv/bias:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_7), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionattn_conv/bias:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_25), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_33), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_28), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_37), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_31), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_41), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_34), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_45), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_37), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_49), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_40), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_53), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_43), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_57), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_46), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_61), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_49), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_65), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_52), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_69), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_55), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_73), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_58), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_77), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_61), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_81), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_64), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_85), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "mask_generator = maskgeneration().prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator.load_weights('_training_checkpoints/mask_model_epoch4_step20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/lib/aarch64-linux-gnu/libgomp.so.1: cannot allocate memory in static TLS block",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnoise_processing\u001b[39m(mask_image, generate_image):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Mask Generator? ?? ???? ?? ???? ???? Noise ??\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m      Noiser? ? ?? ???\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /lib/aarch64-linux-gnu/libgomp.so.1: cannot allocate memory in static TLS block"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def noise_processing(mask_image, generate_image):\n",
    "    \"\"\"\n",
    "    Mask Generator? ?? ???? ?? ???? ???? Noise ??\n",
    "    Args:\n",
    "      mask_image : ??? ? ?? ???\n",
    "      generate_image : model? ?? ??? ???\n",
    "    Return:\n",
    "      Noiser? ? ?? ???\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    noise = np.random.rand(128, 128, 3)*255.0\n",
    "    #k = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    batch = mask_image.shape[0]\n",
    "    #generate_image = (generate_image >= 0.55).astype(np.uint8)\n",
    "    #print(generate_image.shape)\n",
    "    generate_image = generate_image[:, :, :, 0]\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    \n",
    "    for i in range(batch):\n",
    "        image = mask_image[i, :, :, :]\n",
    "        generate_image[i]= cv2.erode(generate_image[i], k)             #  mask  Morphology ?? ???\n",
    "        generate_image[i] = cv2.dilate(generate_image[i], k)\n",
    "        generate_image[i] = (generate_image[i] >= 0.55).astype(np.uint8)\n",
    "        mask = cv2.merge((generate_image[i],generate_image[i],generate_image[i])) ## merging\n",
    "        #print(mask)\n",
    "        #cv2.imshow('mask',mask)\n",
    "        #cv2.waitKey(0)\n",
    "        # mask = cv2.erode(mask, k)             #  mask  Morphology ?? ???\n",
    "        # mask = cv2.dilate(mask, k)\n",
    "        \n",
    "        #mask = (mask + 1) * 127.5\n",
    "        #print(mask)\n",
    "        image = (image + 1) * 127.5\n",
    "        image = image.numpy()\n",
    "        # _, mask = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)   #  mask ???\n",
    "        \n",
    "        # Masking? RGB??? ??? ??\n",
    "        image1 = np.where(mask[:,:,0] == 0, image[:, :, 0], noise[:,:,0])\n",
    "        image2 = np.where(mask[:,:,1] == 0, image[:, :, 1], noise[:,:,1])\n",
    "        image3 = np.where(mask[:,:,2] == 0, image[:, :, 2], noise[:,:,2])\n",
    "\n",
    "        image1 = image1[:, :, np.newaxis]\n",
    "        image2 = image2[:, :, np.newaxis]\n",
    "        image3 = image3[:, :, np.newaxis]\n",
    "\n",
    "        noise_image = np.concatenate([image1, image2], axis=-1)\n",
    "        noise_image = np.concatenate([noise_image, image3], axis=-1)\n",
    "\n",
    "        images.append(noise_image[np.newaxis, :, :, :])\n",
    "\n",
    "    image_input = np.array(images).reshape((batch, 128, 128, 3))\n",
    "    image_input = tf.convert_to_tensor(image_input, dtype=tf.float32)\n",
    "    return (image_input / 127.5) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class facegeneration:\n",
    "    \n",
    "    def prepare_model(self, input_size=(128,128,3),start_channel=32):\n",
    "        inputs_mask = tf.keras.layers.Input(input_size)\n",
    "        #inputs_map = tf.keras.layers.Input(input_size[1])\n",
    "        #inputs = tf.keras.layers.concatenate([inputs_mask, inputs_map])\n",
    "        s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs_mask)\n",
    "\n",
    "        c0 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(s) ##input channel 3 output 16\n",
    "        c0 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c0) ##input channel 3 output 16 \n",
    "        c0 = batch_instance_norm(c0)\n",
    "        c0 = tf.nn.leaky_relu(c0)\n",
    "        p0 = tf.keras.layers.MaxPooling2D((2,2))(c0)\n",
    "        #Contraction path\n",
    "        c1 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p0) ##input channel 3 output 16\n",
    "        c1 = batch_instance_norm(c1)\n",
    "        c1 = tf.nn.leaky_relu(c1)\n",
    "        c1 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c1) ##------>\n",
    "        c1 = batch_instance_norm(c1)\n",
    "        c1 = tf.nn.leaky_relu(c1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1) ##\n",
    "\n",
    "        c2 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p1)\n",
    "        c2 = batch_instance_norm(c2)\n",
    "        c2 = tf.nn.leaky_relu(c2)\n",
    "        c2 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c2) ##------>\n",
    "        c2 = batch_instance_norm(c2)\n",
    "        c2 = tf.nn.leaky_relu(c2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2) ##\n",
    "        \n",
    "        #c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "        c3 = attention1(x=p2,channels=start_channel*8,scope='self_attention')\n",
    "        c3 = batch_instance_norm(c3)\n",
    "        c3 = tf.nn.leaky_relu(c3)\n",
    "        c3 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c3) ##----->\n",
    "        c3 = batch_instance_norm(c3)\n",
    "        c3 = tf.nn.leaky_relu(c3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3) ##\n",
    "        \n",
    "        #c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "        c4 = attention1(x=p3,channels=start_channel*16,scope='self_attention')\n",
    "        c4 = batch_instance_norm(c4)\n",
    "        c4 = tf.nn.leaky_relu(c4)\n",
    "        c4 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c4) ##----->\n",
    "        c4 = batch_instance_norm(c4)\n",
    "        c4 = tf.nn.leaky_relu(c4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4) ##\n",
    "\n",
    "        ##Bottelneck \n",
    "        c5 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(p4)\n",
    "        c5 = batch_instance_norm(c5)\n",
    "        c5 = tf.nn.leaky_relu(c5)\n",
    "        c5 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c5) ##----->\n",
    "        c5 = batch_instance_norm(c5)\n",
    "        c5 = tf.nn.leaky_relu(c5)\n",
    "\n",
    "        #Expansive path \n",
    "        u6 = tf.keras.layers.Conv2DTranspose(start_channel*16, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "        c6 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u6)\n",
    "        c6 = batch_instance_norm(c6)\n",
    "        c6 = tf.nn.leaky_relu(c6)\n",
    "        c6 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c6) ##------>\n",
    "        c6 = batch_instance_norm(c6)\n",
    "        c6 = tf.nn.leaky_relu(c6)\n",
    "        \n",
    "        u7 = tf.keras.layers.Conv2DTranspose(start_channel*8, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "        c7 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u7)\n",
    "        c7 = batch_instance_norm(c7)\n",
    "        c7 = tf.nn.leaky_relu(c7)\n",
    "        c7 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*8, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c7)\n",
    "        c7 = batch_instance_norm(c7)\n",
    "        c7 = tf.nn.leaky_relu(c7)\n",
    "        \n",
    "        u8 = tf.keras.layers.Conv2DTranspose(start_channel*4, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "        c8 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u8)\n",
    "        c8 = batch_instance_norm(c8)\n",
    "        c8 = tf.nn.leaky_relu(c8)\n",
    "        c8 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c8)\n",
    "        c8 = batch_instance_norm(c8)\n",
    "        c8 = tf.nn.leaky_relu(c8)\n",
    "        \n",
    "        u9 = tf.keras.layers.Conv2DTranspose(start_channel*2, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "        c9 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u9)\n",
    "        c9 = batch_instance_norm(c9)\n",
    "        c9 = tf.nn.leaky_relu(c9)\n",
    "        c9 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel*2, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c9)\n",
    "        c9 = batch_instance_norm(c9)\n",
    "        c9 = tf.nn.leaky_relu(c9)\n",
    "\n",
    "        u10 = tf.keras.layers.Conv2DTranspose(start_channel, (2, 2), strides=(2, 2), padding='same')(c9)\n",
    "        u10 = tf.keras.layers.concatenate([u10, c0], axis=3)\n",
    "        c10 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(u10)\n",
    "        c10 = batch_instance_norm(c10)\n",
    "        c10 = tf.nn.leaky_relu(c10)\n",
    "        c10 = SpectralNormalization(tf.keras.layers.Conv2D(start_channel, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))(c10)\n",
    "        c10 = batch_instance_norm(c10)\n",
    "        c10 = tf.nn.leaky_relu(c10)\n",
    "\n",
    "        \n",
    "        outputs = tf.keras.layers.Conv2D(3, (1, 1), activation='tanh')(c10)\n",
    "        \n",
    "        return tf.keras.models.Model(inputs=[inputs_mask], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_67), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_89), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_70), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_93), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_73), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_97), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_76), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_101), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_79), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_105), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_8), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionf_conv/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_9), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentiong_conv/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_10), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionh_conv/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_11), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionattn_conv/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_83), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_110), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_86), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_114), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_12), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionf_conv/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_13), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentiong_conv/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_14), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionh_conv/bias:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_15), but are not present in its tracked objects:   <tf.Variable 'self_attention/self_attentionattn_conv/bias:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_90), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_119), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_93), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_123), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_96), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_127), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_99), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_131), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_102), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_135), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_105), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_139), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(512,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_108), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_143), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_111), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_147), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_114), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_151), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_117), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_155), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_120), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_159), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_123), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_163), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_126), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_167), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_129), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/gamma:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_171), but are not present in its tracked objects:   <tf.Variable 'batch_instance_norm/beta:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "face_generator = facegeneration().prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_generator.load_weights('_training_checkpoints3/generator/face_gen_epoch220_step20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to grab frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        img_name = \"live_image/opencv_frame_0_.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"live_image/opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "  mask_image = image_load(image_file)\n",
    "  mask_image = resize_and_normalize(mask_image, None, 128, 128)\n",
    "\n",
    "  return mask_image\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 626ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected image array to have rank 3 (single image). Got array with shape: (1, 128, 128, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask_generator\u001b[38;5;241m.\u001b[39mpredict(mask_face)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#image = noise_processing(mask_face, mask)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m image \u001b[38;5;241m=\u001b[39m face_generator(\u001b[43marray_to_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_preprocessing/image/utils.py:256\u001b[0m, in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected image array to have rank 3 (single image). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot array with shape: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (x\u001b[38;5;241m.\u001b[39mshape,))\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid data_format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m data_format)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (1, 128, 128, 1)"
     ]
    }
   ],
   "source": [
    "TEST_MASK_FACE_PATH = 'live_image'\n",
    "test_files = os.listdir(TEST_MASK_FACE_PATH)\n",
    "test_files = [TEST_MASK_FACE_PATH+'/'+fileanme for fileanme in natsort.natsorted(test_files)]\n",
    "\n",
    "test_dataset = tf.data.Dataset.list_files(test_files, shuffle=False)\n",
    "test_dataset = test_dataset.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "for step, (mask_face )in enumerate(test_dataset):\n",
    "  mask = mask_generator.predict(mask_face)\n",
    "  #image = noise_processing(mask_face, mask)\n",
    "  image = face_generator(mask, training=False)\n",
    "  if step == 1:\n",
    "    break\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(141)\n",
    "#plt.imshow(array_to_img(image[0]))\n",
    "#plt.subplot(142)\n",
    "plt.imshow(array_to_img(mask[0]))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
